{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyNwHwk8nUa64n4RJpp4nrZ7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"k3w3iI37xrd9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","import numpy as np\n","import cv2 as cv\n","import sys\n","\n","print(sys.version)\n","print(cv.__version__)\n","print(np.__version__)\n","print(tf.__version__)\n","print(keras.__version__)"],"metadata":{"id":"beFvdkn1xrgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","\n","# 파일 경로 입력\n","zip_file_name = '' # 압축을 풀 zip파일의 경로를 입력하세요\n","\n","# 압축 해제할 경로 입력\n","extraction_dir = '/content/dataset' # 압축해제할 경로를 입력하세요\n","\n","# 압축 해제\n","with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n","    zip_ref.extractall(extraction_dir)"],"metadata":{"id":"i5s7nqkixrja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from imutils import paths\n","\n","search_dir = \"/content/dataset/emotion_images/data\" #train data를 불러올 경로를 입력하세요\n","\n","search_dir_anger = \"/content/dataset/emotion_images/data/anger\"\n","\n","search_dir_happy = \"/content/dataset/emotion_images/data/happy\"\n","\n","search_dir_normal = \"/content/dataset/emotion_images/data/normal\"\n","search_dir_sad = \"/content/dataset/emotion_images/data/sad\"\n","search_dir_worry = \"/content/dataset/emotion_images/data/worry\"\n","\n","image_paths = sorted(\n","    list(paths.list_images(search_dir))\n",")\n","\n","image_paths_anger = sorted(\n","    list(paths.list_images(search_dir_anger))\n",")\n","image_paths_happy = sorted(\n","    list(paths.list_images(search_dir_happy))\n",")\n","image_paths_normal = sorted(\n","    list(paths.list_images(search_dir_normal))\n",")\n","image_paths_sad = sorted(\n","    list(paths.list_images(search_dir_sad))\n",")\n","image_paths_worry = sorted(\n","    list(paths.list_images(search_dir_worry))\n",")\n","\n","print(\">>> total images =\", len(image_paths))\n","\n","print(\">>> anger images =\", len(image_paths_anger))\n","print(\">>> happy images =\", len(image_paths_happy))\n","print(\">>> normal images =\", len(image_paths_normal))\n","print(\">>> sad images =\", len(image_paths_sad))\n","print(\">>> worry images =\", len(image_paths_worry))"],"metadata":{"id":"coRbyZzPxrlU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","from tqdm import tqdm\n","\n","image_dim = (180, 180, 3)\n","\n","images = []\n","labels = []\n","for image_path in tqdm(image_paths):\n","    image = cv2.imread(image_path)\n","\n","    image = cv2.resize(\n","        image, (image_dim[1], image_dim[0])\n","    )\n","    images.append(image)\n","\n","    label = image_path.split(os.path.sep)[-2]\n","    labels.append([label])\n","\n","print(\">>> images count =\", len(images))"],"metadata":{"id":"IQJhaU8Fxrm_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","images = np.array(images, dtype='float32') / 255.0\n","labels = np.array(labels)\n","\n","mlb = MultiLabelBinarizer()\n","enc_labels = mlb.fit_transform(labels)\n","\n","print(f'label shape = {labels}')\n","print(f'mlb 값 : {mlb}')\n","print(f'enc_labels : {enc_labels}')\n","print(\">>> classes name =\", mlb.classes_)"],"metadata":{"id":"DU5kaJrqxrpE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","seed = 47\n","\n","(x_train, x_test, y_train, y_test) = train_test_split(\n","    images, enc_labels, test_size=0.2, random_state=seed\n",")\n","print(\">> train test shape = {} {}\".format(\n","    x_train.shape, y_train.shape)\n",")"],"metadata":{"id":"VMwr_lnfxrq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import하여 모델 구현\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n","from tensorflow.keras.applications import ResNet50\n","\n","# ResNet50 모델 불러오기 (ImageNet 사전 훈련된 가중치 사용, 최상위 레이어 포함하지 않음)\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(180, 180, 3))\n","\n","# 모델의 출력 레이어 제거 및 새로운 출력 레이어 추가\n","x = base_model.output\n","x = GlobalAveragePooling2D(keepdims=True)(x)  # keepdims=True 설정\n","x = Flatten()(x)  # 1차원으로 평탄화\n","output = Dense(len(mlb.classes_), activation='softmax')(x)  # 분류할 클래스 수에 맞게 설정\n","\n","# 새로운 모델 정의\n","model = Model(inputs=base_model.input, outputs=output)\n","\n","# 모델 구조 확인\n","model.summary()\n"],"metadata":{"id":"gynZ2dDTxru2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 증강 설정\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","aug = ImageDataGenerator(\n","    rotation_range=25, width_shift_range=0.1, height_shift_range=0.1,\n","    shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest'\n",")"],"metadata":{"id":"virn9ZEexrwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 옵티마이저 및 손실 함수 설정\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.optimizers import Adam\n","learning_rate = 1e-3\n","optimizer = Adam(\n","    learning_rate=learning_rate,\n","    beta_1=0.9, beta_2=0.999, epsilon=1e-07\n",")\n","loss = CategoricalCrossentropy(from_logits=False)"],"metadata":{"id":"GBHVPYgRxryo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 컴파일\n","model.compile(\n","    loss=loss,\n","    optimizer=optimizer,\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"w3mKdlvtxr0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 요약 출력\n","model.summary()"],"metadata":{"id":"fs7tPy5-xr2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    aug.flow(x_train, y_train, batch_size=128),\n","    validation_data=(x_test, y_test),\n","    steps_per_epoch=len(x_train) // 128,\n","    epochs=200, verbose=1\n",")"],"metadata":{"id":"9YqDZDw-xr4N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_image_paths = sorted(\n","    list(\n","        paths.list_images(\"\") #유효성 검사를 위한 이미지를 불러올 파일 경로를 입력하세요\n","    )\n",")\n","print(\">>> test image path =\", test_image_paths)"],"metadata":{"id":"y0qsROxbxr6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","import cv2\n","import numpy as np\n","\n","print(\">>> class index =\", mlb.classes_)\n","\n","for image_path in test_image_paths:\n","    test_image = cv2.imread(image_path)\n","\n","    if test_image is None:\n","        print(f\"Error loading image {image_path}\")\n","        continue\n","\n","    # 이미지 리사이징\n","    test_image = cv2.resize(test_image, (180, 180))  # 모델이 예상하는 크기로 조정\n","\n","    cv2_imshow(test_image)\n","\n","    # 이미지 전처리\n","    test_image = test_image.astype(\"float32\") / 255.0\n","    test_image = np.expand_dims(test_image, axis=0)\n","\n","    try:\n","        # 모델 예측\n","        proba = model.predict(test_image)[0]\n","        print(np.round(proba, 3))\n","        idx = np.argmax(proba)\n","        print(\">>> predict class =\", mlb.classes_[idx])\n","        print(f\">>> actual class = {image_path.split(os.path.sep)[-1]}\")\n","    except Exception as e:\n","        print(f\"Error predicting image {image_path}: {e}\")"],"metadata":{"id":"55kGaYf_xr8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 전체 저장\n","model.save('')# 모델을 저장할 경로를 입력하세요\n"],"metadata":{"id":"EWx01Jj6yHjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 가중치만 저장\n","model.save_weights('') # 가중치를 저장할 경로를 입력하세요"],"metadata":{"id":"RwJzQGccxr99"},"execution_count":null,"outputs":[]}]}